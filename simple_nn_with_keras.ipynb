{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple-nn-with-keras",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanocha/try-tensorflow/blob/master/simple_nn_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7vrcL_U9JyV",
        "colab_type": "code",
        "outputId": "5eb325e7-31f7-4866-e565-4fe3b8769a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape([60000, -1])\n",
        "X_test = X_test.reshape([10000, -1])\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "mean_vals = np.mean(X_train, axis=0)\n",
        "std_val = np.std(X_train)\n",
        "\n",
        "X_train_centered = (X_train - mean_vals) / std_val\n",
        "X_test_centered = (X_test - mean_vals) / std_val\n",
        "\n",
        "print(X_train_centered.shape, y_train.shape)\n",
        "print(X_test_centered.shape, y_test.shape)\n",
        "\n",
        "print(y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 784)\n",
            "(10000, 784)\n",
            "(60000, 784) (60000,)\n",
            "(10000, 784) (10000,)\n",
            "[5 0 4 ... 5 6 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZC_rUfa9Yh2",
        "colab_type": "code",
        "outputId": "9babc121-7e79-4e7e-d8d2-9b23c7447196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "np.random.seed(12)\n",
        "tf.set_random_seed(123)\n",
        "\n",
        "y_train_onehot = keras.utils.to_categorical(y_train)\n",
        "print(y_train[:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wch2y1g9yET",
        "colab_type": "code",
        "outputId": "735466a7-d652-492b-e1c3-b8356b21103c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "        units=50,\n",
        "        input_dim=X_train_centered.shape[1],\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        bias_initializer='zeros',\n",
        "        activation='tanh',\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "        units=50,\n",
        "        input_dim=50,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        bias_initializer='zeros',\n",
        "        activation='tanh',\n",
        "    )   \n",
        ")\n",
        "\n",
        "model.add(\n",
        "    keras.layers.Dense(\n",
        "        units=y_train_onehot.shape[1],\n",
        "        input_dim=50,\n",
        "        kernel_initializer='glorot_uniform',\n",
        "        bias_initializer='zeros',\n",
        "        activation='softmax',\n",
        "    )\n",
        ")\n",
        "\n",
        "sgd_optimizer = keras.optimizers.SGD(\n",
        "    lr=0.001,\n",
        "    decay=1e-7,\n",
        "    momentum=.9,\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=sgd_optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_centered,\n",
        "    y_train_onehot,\n",
        "    batch_size=64,\n",
        "    epochs=50,\n",
        "    verbose=1,\n",
        "    validation_split=0.1,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/50\n",
            "54000/54000 [==============================] - 2s 42us/sample - loss: 0.7229 - val_loss: 0.3539\n",
            "Epoch 2/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.3630 - val_loss: 0.2659\n",
            "Epoch 3/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.2974 - val_loss: 0.2292\n",
            "Epoch 4/50\n",
            "54000/54000 [==============================] - 2s 31us/sample - loss: 0.2612 - val_loss: 0.2075\n",
            "Epoch 5/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.2365 - val_loss: 0.1911\n",
            "Epoch 6/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.2176 - val_loss: 0.1807\n",
            "Epoch 7/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.2024 - val_loss: 0.1709\n",
            "Epoch 8/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.1898 - val_loss: 0.1633\n",
            "Epoch 9/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1784 - val_loss: 0.1583\n",
            "Epoch 10/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1689 - val_loss: 0.1526\n",
            "Epoch 11/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1602 - val_loss: 0.1480\n",
            "Epoch 12/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.1525 - val_loss: 0.1437\n",
            "Epoch 13/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1454 - val_loss: 0.1394\n",
            "Epoch 14/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1389 - val_loss: 0.1378\n",
            "Epoch 15/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1331 - val_loss: 0.1345\n",
            "Epoch 16/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1277 - val_loss: 0.1332\n",
            "Epoch 17/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.1227 - val_loss: 0.1301\n",
            "Epoch 18/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1180 - val_loss: 0.1286\n",
            "Epoch 19/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1135 - val_loss: 0.1267\n",
            "Epoch 20/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1093 - val_loss: 0.1258\n",
            "Epoch 21/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1056 - val_loss: 0.1245\n",
            "Epoch 22/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.1018 - val_loss: 0.1228\n",
            "Epoch 23/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0984 - val_loss: 0.1219\n",
            "Epoch 24/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0951 - val_loss: 0.1216\n",
            "Epoch 25/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0920 - val_loss: 0.1210\n",
            "Epoch 26/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0890 - val_loss: 0.1201\n",
            "Epoch 27/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0863 - val_loss: 0.1196\n",
            "Epoch 28/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0835 - val_loss: 0.1187\n",
            "Epoch 29/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0811 - val_loss: 0.1182\n",
            "Epoch 30/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0785 - val_loss: 0.1187\n",
            "Epoch 31/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0761 - val_loss: 0.1179\n",
            "Epoch 32/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0740 - val_loss: 0.1177\n",
            "Epoch 33/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0719 - val_loss: 0.1164\n",
            "Epoch 34/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0698 - val_loss: 0.1167\n",
            "Epoch 35/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0678 - val_loss: 0.1169\n",
            "Epoch 36/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0660 - val_loss: 0.1161\n",
            "Epoch 37/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0641 - val_loss: 0.1157\n",
            "Epoch 38/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0624 - val_loss: 0.1163\n",
            "Epoch 39/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0607 - val_loss: 0.1155\n",
            "Epoch 40/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0590 - val_loss: 0.1157\n",
            "Epoch 41/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0576 - val_loss: 0.1160\n",
            "Epoch 42/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0560 - val_loss: 0.1153\n",
            "Epoch 43/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0547 - val_loss: 0.1156\n",
            "Epoch 44/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0532 - val_loss: 0.1158\n",
            "Epoch 45/50\n",
            "54000/54000 [==============================] - 2s 32us/sample - loss: 0.0519 - val_loss: 0.1149\n",
            "Epoch 46/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0506 - val_loss: 0.1154\n",
            "Epoch 47/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0493 - val_loss: 0.1145\n",
            "Epoch 48/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0481 - val_loss: 0.1155\n",
            "Epoch 49/50\n",
            "54000/54000 [==============================] - 2s 33us/sample - loss: 0.0469 - val_loss: 0.1155\n",
            "Epoch 50/50\n",
            "54000/54000 [==============================] - 2s 34us/sample - loss: 0.0458 - val_loss: 0.1156\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ocxtvNR_Nmq",
        "colab_type": "code",
        "outputId": "c9fb4564-42fd-40d8-88d9-3a6c177870d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_train_pred = model.predict_classes(\n",
        "    X_train_centered,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "print(y_train_pred[:3])\n",
        "\n",
        "correnct_preds = np.sum(y_train == y_train_pred, axis = 0)\n",
        "train_acc = correnct_preds / y_train.shape[0]\n",
        "\n",
        "print(train_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5 0 4]\n",
            "0.9898166666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOKU5qWb_0vR",
        "colab_type": "code",
        "outputId": "71c11d97-0bc4-4e8d-e528-c4dd7d17cd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_test_pred = model.predict_classes(\n",
        "    X_test_centered,\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "print(y_test_pred[:3])\n",
        "\n",
        "correnct_preds = np.sum(y_test == y_test_pred, axis = 0)\n",
        "test_acc = correnct_preds /y_test.shape[0]\n",
        "\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[7 2 1]\n",
            "0.964\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}