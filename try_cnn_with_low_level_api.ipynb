{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "try_cnn_with_low_level_api.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanocha/try-tensorflow/blob/master/try_cnn_with_low_level_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHvgIPQZKSGq",
        "colab_type": "code",
        "outputId": "0b000556-e866-4c63-cd6b-d08bf855b5d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_data, y_data), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train, y_train = X_data[:50000, :], y_data[:50000]\n",
        "X_valid, y_valid = X_data[50000:, :], y_data[50000:]\n",
        "\n",
        "X_train = X_train.reshape([50000, -1])\n",
        "X_valid = X_valid.reshape([10000, -1])\n",
        "X_test = X_test.reshape([10000, -1])\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "mean_vals = np.mean(X_train, axis=0)\n",
        "std_val = np.std(X_train)\n",
        "\n",
        "X_train_centered = (X_train - mean_vals) / std_val\n",
        "X_valid_centered = X_valid - mean_vals\n",
        "X_test_centered = (X_test - mean_vals) / std_val\n",
        "\n",
        "print(X_train_centered.shape, y_train.shape)\n",
        "print(X_valid_centered.shape, y_valid.shape)\n",
        "print(X_test_centered.shape, y_test.shape)\n",
        "\n",
        "print(y_train)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(50000, 784)\n",
            "(10000, 784)\n",
            "(10000, 784)\n",
            "(50000, 784) (50000,)\n",
            "(10000, 784) (10000,)\n",
            "(10000, 784) (10000,)\n",
            "[5 0 4 ... 8 4 8]\n",
            "(50000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5zDuuvXKYZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def batch_generator(X, y, batch_size=64, shuffle=False, random_seed=None):\n",
        "  idx = np.arange(y.shape[0])\n",
        "\n",
        "  if shuffle:\n",
        "    rng = np.random.RandomState(random_seed)\n",
        "    rng.shuffle(idx)\n",
        "    X = X[idx]\n",
        "    y = y[idx]\n",
        "\n",
        "  for i in range(0, X.shape[0], batch_size):\n",
        "    yield(\n",
        "        X[i:i+batch_size, :],\n",
        "        y[i:i+batch_size],\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GryK3rwXLB0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_layer(input_tensor, name, kernel_size, n_output_channels, padding_mode='SAME', strides=(1, 1, 1, 1)):\n",
        "  with tf.variable_scope(name):\n",
        "    input_shape = input_tensor.get_shape().as_list()\n",
        "    n_input_channels = input_shape[-1]\n",
        "\n",
        "    weights_shape = (\n",
        "        list(kernel_size) + [n_input_channels, n_output_channels]\n",
        "    )\n",
        "\n",
        "    weights = tf.get_variable(name='_weights', shape=weights_shape)\n",
        "    print(weights)\n",
        "\n",
        "    biases = tf.get_variable(name='_biases', initializer=tf.zeros(shape=[n_output_channels]))\n",
        "    print(biases)\n",
        "\n",
        "    conv = tf.nn.conv2d(\n",
        "        input = input_tensor,\n",
        "        filter = weights,\n",
        "        strides = strides,\n",
        "        padding = padding_mode,\n",
        "    )\n",
        "    print(conv)\n",
        "\n",
        "    conv = tf.nn.bias_add(conv, biases, name='net_pre-activation')\n",
        "    print(conv)\n",
        "\n",
        "    conv = tf.nn.relu(conv, name='activation')\n",
        "    print(conv)\n",
        "\n",
        "    return conv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Xj309hNQCQT",
        "colab_type": "code",
        "outputId": "7353eb55-50ea-4aff-e481-c67f9b564118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "  x = tf.placeholder(\n",
        "      tf.float32,\n",
        "      shape=[None, 28, 28, 1],\n",
        "  )\n",
        "\n",
        "  conv_layer(x, name='convtest', kernel_size=(3, 3), n_output_channels=32)\n",
        "\n",
        "del g, x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'convtest/_weights:0' shape=(3, 3, 1, 32) dtype=float32_ref>\n",
            "<tf.Variable 'convtest/_biases:0' shape=(32,) dtype=float32_ref>\n",
            "Tensor(\"convtest/Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Tensor(\"convtest/net_pre-activation:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
            "Tensor(\"convtest/activation:0\", shape=(?, 28, 28, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V5wljMiQbwh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fc_layer(input_tensor, name, n_output_units, activation_fn=None):\n",
        "  with tf.variable_scope(name):\n",
        "    input_shape = input_tensor.get_shape().as_list()[1:]\n",
        "    n_input_units = np.prod(input_shape)\n",
        "\n",
        "    if len(input_shape) > 1:\n",
        "      input_tensor = tf.reshape(input_tensor, shape=(-1, n_input_units))\n",
        "\n",
        "    weights_shape = [n_input_units, n_output_units]\n",
        "    weights = tf.get_variable(name='_weights', shape=weights_shape)\n",
        "    print(weights)\n",
        "    \n",
        "    biases = tf.get_variable(name='_biases', initializer=tf.zeros(shape=[n_output_units]))\n",
        "    print(biases)\n",
        "\n",
        "    layer = tf.matmul(input_tensor, weights)\n",
        "    print(layer)\n",
        "\n",
        "    layer = tf.nn.bias_add(layer, biases, name='net_pre-activation')\n",
        "    print(layer)\n",
        "\n",
        "    if activation_fn is None:\n",
        "      return layer\n",
        "    \n",
        "    layer = activation_fn(layer, name='activation')\n",
        "    print(layer)\n",
        "    return layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CObw8xNBStjL",
        "colab_type": "code",
        "outputId": "74b4674c-8255-44a5-c133-71d13d0b139c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "g = tf.Graph()\n",
        "\n",
        "with g.as_default():\n",
        "  x = tf.placeholder(\n",
        "      tf.float32,\n",
        "      shape=[None, 28, 28, 1],\n",
        "  )\n",
        "\n",
        "  fc_layer(x, name='fctest', n_output_units=32, activation_fn=tf.nn.relu)\n",
        "\n",
        "del g, x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'fctest/_weights:0' shape=(784, 32) dtype=float32_ref>\n",
            "<tf.Variable 'fctest/_biases:0' shape=(32,) dtype=float32_ref>\n",
            "Tensor(\"fctest/MatMul:0\", shape=(?, 32), dtype=float32)\n",
            "Tensor(\"fctest/net_pre-activation:0\", shape=(?, 32), dtype=float32)\n",
            "Tensor(\"fctest/activation:0\", shape=(?, 32), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEILPAV1PpBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_cnn():\n",
        "  tf_x = tf.placeholder(tf.float32, shape=[None, 784], name='tf_x')\n",
        "  tf_y = tf.placeholder(tf.int32, shape=[None], name='tf_y')\n",
        "\n",
        "  tf_x_image = tf.reshape(tf_x, shape=[-1, 28, 28, 1], name='tf_x_reshaped')\n",
        "  tf_y_onehot = tf.one_hot(\n",
        "      indices=tf_y,\n",
        "      depth=10,\n",
        "      dtype=tf.float32,\n",
        "      name='tf_y_onehot',\n",
        "  )\n",
        "\n",
        "  h1 = conv_layer(\n",
        "      tf_x_image,\n",
        "      name='conv_1',\n",
        "      kernel_size=(5,5),\n",
        "      padding_mode='VALID',\n",
        "      n_output_channels=32,\n",
        "  )\n",
        "  \n",
        "  h1_pool = tf.nn.max_pool(\n",
        "      h1,\n",
        "      ksize=[1, 2, 2, 1],\n",
        "      strides=[1, 2, 2, 1],\n",
        "      padding='SAME',\n",
        "  )\n",
        "\n",
        "  h2 = conv_layer(\n",
        "      h1_pool,\n",
        "      name='conv_2',\n",
        "      kernel_size=(5,5),\n",
        "      padding_mode='VALID',\n",
        "      n_output_channels=64,\n",
        "  )\n",
        "\n",
        "  h2_pool = tf.nn.max_pool(\n",
        "      h2,\n",
        "      ksize=[1, 2, 2, 1],\n",
        "      strides=[1, 2, 2, 1],\n",
        "      padding='SAME',\n",
        "  )\n",
        "\n",
        "  h3 = fc_layer(\n",
        "      h2_pool,\n",
        "      name='fc_3',\n",
        "      n_output_units=1024,\n",
        "      activation_fn=tf.nn.relu,\n",
        "  )\n",
        "\n",
        "  keep_prob = tf.placeholder(tf.float32, name='fc_keep_prob')\n",
        "  h3_drop = tf.nn.dropout(h3, keep_prob=keep_prob, name='dropout_layer')\n",
        "\n",
        "  h4 = fc_layer(\n",
        "      h3_drop,\n",
        "      name='fc_4',\n",
        "      n_output_units=10,\n",
        "      activation_fn=None,\n",
        "  )\n",
        "\n",
        "  predictions = {\n",
        "      'probabilities': tf.nn.softmax(h4, name='probabilities'),\n",
        "      'labels': tf.cast(tf.argmax(h4, axis=1), tf.int32, name='labels'),\n",
        "  }\n",
        "\n",
        "  cross_entropy_loss = tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          logits=h4,\n",
        "          labels=tf_y_onehot,\n",
        "      ),\n",
        "      name='cross_entropy_loss',\n",
        "  )\n",
        "\n",
        "  optimizer = tf.train.AdamOptimizer(leaning_rate)\n",
        "  optimizer = optimizer.minimize(cross_entropy_loss, name='train_op')\n",
        "\n",
        "  correct_predictions = tf.equal(predictions['labels'], tf_y, name='correct_preds')\n",
        "  accuracy = tf.reduce_mean(\n",
        "      tf.cast(correct_predictions, tf.float32),\n",
        "      name='accuracy',\n",
        "  )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd7Wn65dTHkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save(saver, sess, epoch, path='./model/'):\n",
        "  if not os.path.isdir(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "  saver.save(sess, os.path.join(path, 'cnn-model.ckpt'), global_step=epoch)\n",
        "\n",
        "\n",
        "def load(saver, sess, path, epoch):\n",
        "  saver.restore(sess, os.path.join(path, 'cnn-model.ckpt-%d' % epoch))\n",
        "\n",
        "\n",
        "def train(sess, training_set, validation_set=None, initialize=True, epochs=20, shuffle=True, dropout=0.5, random_seed=None):\n",
        "  X_data = np.array(training_set[0])\n",
        "  y_data = np.array(training_set[1])\n",
        "  training_loss = []\n",
        "\n",
        "  if initialize:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  np.random.seed(random_seed)\n",
        "\n",
        "  for epoch in range(1, epochs + 1):\n",
        "    batch_gen = batch_generator(X_data, y_data, shuffle=shuffle)\n",
        "    avg_loss = 0.0\n",
        "\n",
        "    for i, (batch_X, batch_y) in enumerate(batch_gen):\n",
        "      feed = {\n",
        "          'tf_x:0': batch_X,\n",
        "          'tf_y:0': batch_y,\n",
        "          'fc_keep_prob:0': dropout,\n",
        "      }\n",
        "      loss, _ = sess.run(\n",
        "          ['cross_entropy_loss:0', 'train_op'],\n",
        "          feed_dict=feed,\n",
        "      )\n",
        "\n",
        "      avg_loss += loss\n",
        "\n",
        "    training_loss.append(avg_loss / (i+1))\n",
        "    print('epoch %02d training avg loss: %7.3f' % (epoch, avg_loss), end=' ')\n",
        "\n",
        "    if validation_set is not None:\n",
        "      feed = {\n",
        "          'tf_x:0': validation_set[0],\n",
        "          'tf_y:0': validation_set[1],\n",
        "          'fc_keep_prob:0': 1.0,\n",
        "      }\n",
        "\n",
        "      valid_acc = sess.run('accuracy:0', feed_dict=feed)\n",
        "      print(' validation acc: %7.3f' % valid_acc)\n",
        "\n",
        "    else:\n",
        "      print()\n",
        "\n",
        "\n",
        "def predict(sess, X_test, return_proba=False):\n",
        "  feed = {\n",
        "      'tf_x:0': X_test,\n",
        "      'fc_keep_prob:0': 1.0,\n",
        "  }\n",
        "\n",
        "  if return_proba:\n",
        "    return sess.run('probabilities:0', feed_dict=feed)\n",
        "  else:\n",
        "    return sess.run('labels:0', feed_dict=feed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oCIBHvTWHU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "c0caf468-f5f1-4beb-aa6b-637328fdc610"
      },
      "source": [
        "leaning_rate = 1e-4\n",
        "random_seed = 123\n",
        "\n",
        "g = tf.Graph()\n",
        "with g.as_default():\n",
        "  tf.set_random_seed(random_seed)\n",
        "  build_cnn()\n",
        "  saver = tf.train.Saver()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'conv_1/_weights:0' shape=(5, 5, 1, 32) dtype=float32_ref>\n",
            "<tf.Variable 'conv_1/_biases:0' shape=(32,) dtype=float32_ref>\n",
            "Tensor(\"conv_1/Conv2D:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
            "Tensor(\"conv_1/net_pre-activation:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
            "Tensor(\"conv_1/activation:0\", shape=(?, 24, 24, 32), dtype=float32)\n",
            "<tf.Variable 'conv_2/_weights:0' shape=(5, 5, 32, 64) dtype=float32_ref>\n",
            "<tf.Variable 'conv_2/_biases:0' shape=(64,) dtype=float32_ref>\n",
            "Tensor(\"conv_2/Conv2D:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
            "Tensor(\"conv_2/net_pre-activation:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
            "Tensor(\"conv_2/activation:0\", shape=(?, 8, 8, 64), dtype=float32)\n",
            "<tf.Variable 'fc_3/_weights:0' shape=(1024, 1024) dtype=float32_ref>\n",
            "<tf.Variable 'fc_3/_biases:0' shape=(1024,) dtype=float32_ref>\n",
            "Tensor(\"fc_3/MatMul:0\", shape=(?, 1024), dtype=float32)\n",
            "Tensor(\"fc_3/net_pre-activation:0\", shape=(?, 1024), dtype=float32)\n",
            "Tensor(\"fc_3/activation:0\", shape=(?, 1024), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-8-fbed0d6bf1ff>:51: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<tf.Variable 'fc_4/_weights:0' shape=(1024, 10) dtype=float32_ref>\n",
            "<tf.Variable 'fc_4/_biases:0' shape=(10,) dtype=float32_ref>\n",
            "Tensor(\"fc_4/MatMul:0\", shape=(?, 10), dtype=float32)\n",
            "Tensor(\"fc_4/net_pre-activation:0\", shape=(?, 10), dtype=float32)\n",
            "WARNING:tensorflow:From <ipython-input-8-fbed0d6bf1ff>:68: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUfa8m2xWf1y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "outputId": "64573f68-076f-4011-805c-65fc5748c249"
      },
      "source": [
        "with tf.Session(graph=g) as sess:\n",
        "  train(\n",
        "      sess,\n",
        "      training_set=(X_train_centered, y_train),\n",
        "      validation_set=(X_valid_centered, y_valid),\n",
        "      initialize=True,\n",
        "      random_seed=123,\n",
        "  )\n",
        "\n",
        "  save(saver, sess, epoch=20)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 01 training avg loss: 271.591  validation acc:   0.974\n",
            "epoch 02 training avg loss:  74.593  validation acc:   0.983\n",
            "epoch 03 training avg loss:  51.872  validation acc:   0.985\n",
            "epoch 04 training avg loss:  39.070  validation acc:   0.987\n",
            "epoch 05 training avg loss:  32.101  validation acc:   0.988\n",
            "epoch 06 training avg loss:  26.963  validation acc:   0.988\n",
            "epoch 07 training avg loss:  23.310  validation acc:   0.988\n",
            "epoch 08 training avg loss:  20.142  validation acc:   0.990\n",
            "epoch 09 training avg loss:  17.318  validation acc:   0.992\n",
            "epoch 10 training avg loss:  15.006  validation acc:   0.992\n",
            "epoch 11 training avg loss:  12.027  validation acc:   0.989\n",
            "epoch 12 training avg loss:  11.698  validation acc:   0.990\n",
            " validation acc:   0.992\n",
            "epoch 14 training avg loss:   8.956  validation acc:   0.991\n",
            "epoch 15 training avg loss:   7.381  validation acc:   0.992\n",
            "epoch 16 training avg loss:   6.850  validation acc:   0.991\n",
            "epoch 17 training avg loss:   6.977  validation acc:   0.991\n",
            "epoch 18 training avg loss:   6.239  validation acc:   0.992\n",
            "epoch 19 training avg loss:   5.519  validation acc:   0.991\n",
            "epoch 20 training avg loss:   4.664  validation acc:   0.992\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-4d4a2917a4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m   )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-0ebaeff3b991>\u001b[0m in \u001b[0;36msave\u001b[0;34m(saver, sess, epoch, path)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./model/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cnn-model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wjHd7X2WwQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}